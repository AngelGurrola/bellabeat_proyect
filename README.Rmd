---
title: "Bellabeat: proyecto final"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Contenido
- Primero
- Segundo

## Contexto
En este proyecto simulamos trabajar para la empresa Bellabeat.
Urška Sršen y Sando Mur fundaron Bellabeat, una empresa de alta tecnología que fabrica productos inteligentes focalizados en el cuidado de la salud.

¿Qué ha hecho?

  - Invirtió en medios tradicionales y en marketing digital
  - Invierte en google search y mantiene activas sus redes sociales
  - Anuncios de video en YT y avisos publicitarios en Red de Display Google en fechas clave.
 
Orden de trabajo:

Concentrarse en un producto Bellabeat y analizar losdatos de uso de dispositivos inteligentes para conocer cómo las personas están usando sus dispositivos inteligentes. Emitir recomendaciones de alto nivel sobre cómo estas tendencias pueden colaborar en la estrategia de marketing de Bellabeat.


## Paso cero

A modo de replicar mi trabajo en el futuro desde una perspectiva donde no recuerde absolutamente nada de lo que estoy haciendo ahora mismo, vi necesario incluir este paso donde primero tuve que decidir en que plataforma realizaria la publicación de mi trabajo y resolví que github es la plataforma más actualizada que ademas de alojar mi proyecto serviría para aprender a utilizar esta herramienta de control de versiones y que tambien me ayudaría a crear un portafolio inicial.

Tuve que aprender desde como crear un archivo README en R a conectar Git desde la misma interfaz de R studio y añadí mi proyecto a github utilizando las siguientes lineas de comandos:

- git remote add origin https://github.com/AngelGurrola/bellabeat_proyect.git
- git branch -M main
- git push -u origin main

Utilice el video tutorial de Riffomonas Project para aprender como conectar RStudio con github disponible en: https://www.youtube.com/watch?v=bUoN85QvC10&t=505s

Una vez teniendo la plataforma lista comence con mi proyecto de analisis de datos para Bellabeat.

## Preparar

Comenzamos con importar el conjunto de datos: descargamos la carpeta comprimida desde: https://www.kaggle.com/datasets/arashnic/fitbit

Al descomprimir la carpeta de datos se observan 18 tablas con un peso de 322 MB en donde los titulos de cada una nos dan contexto del contenido y el peso de las mismas nos ayudan a dimensionar la cantidad de datos que poseen, siendo la tabla heartrate_seconds_merged la más pesada con 87.4  MB y weightLogInfo_merged la mas lígera con 7 KB. 

Se añadieron todos los archivos al directorio de trabajo despues de darles un vistazo rápido desde hoja de cálculo.

La tabla base desde obtendremos las primeras hipotesis será dailyActivity_merged, la cual provee un resumen diario de los totales de información recolectada por los dispositivos de Bellabeat.

Entonces se procede a importar las tablas como conjunto de datos de R.
```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(tidyverse)
pesos <- read.csv(file="C://Users//an_96//Documents//Bellabeat//Bellabeat//archive//Fitabase Data 4.12.16-5.12.16//weightLogInfo_merged.csv")
pasos <- read.csv(file="C://Users//an_96//Documents//Bellabeat//Bellabeat//archive//Fitabase Data 4.12.16-5.12.16//hourlySteps_merged.csv")
diario <- read.csv(file="C://Users//an_96//Documents//Bellabeat//Bellabeat//archive//Fitabase Data 4.12.16-5.12.16//dailyActivity_merged.csv")
sueño <- read.csv(file="C://Users//an_96//Documents//Bellabeat//Bellabeat//archive//Fitabase Data 4.12.16-5.12.16//sleepDay_merged.csv")
calorias <- read.csv(file="C://Users//an_96//Documents//Bellabeat//Bellabeat//archive//Fitabase Data 4.12.16-5.12.16//dailyCalories_merged.csv")
```

Durante la revisión rápida en hojas de cálculo se observaron notables diferencias en la cantidad de datos, por lo tanto, se procedió a confirmar la cantidad de Id que contenian algunas de las tablas.

```{r}
n_distinct(pesos$Id)
n_distinct(pasos$Id)
n_distinct(diario$Id)
n_distinct(sueño$Id)
n_distinct(calorias$Id)
```
Se observa como la tabla de pesos incluye unicamente los datos de 8 individuos por lo que deja de ser relevante para el analisis al no ser una variable que incluyan en todas las tablas.

Así como que la tabla de sueño contiene únicamente los registros de 24 usuarios.

*Desde este punto considero importante mantener un registro más habitual del peso de los usuarios mediante una notificación de recordatorio a registrar tu peso.*

Para explorar las tablas se utilizó la libreria de tidyverse

```{r}
glimpse(diario)
```
De esta exploracion se observa que la fecha podría convertirse en un formato ISO para facilitar el analisis así como el tipo de datos que se tienen en las distintas columnas.

Para obtener una mayor descripción de los datos utilizo la siguiente función para obtener un resumen de los datos en la tabla de "diario".

```{r}
summary(diario)
```

Desde este punto se pueden determinar las respuestas a las preguntas clave de esta parte del reto: 

Los datos tienen un formato largo y se organizan en 18 tablas almacenadas en archivos csv.
Se detectan grandes problemas de sesgo al tener únicamente 33 usuarios de los cuales no se añaden contexto demográfico como su ubicación, edad, sexo (se infiere que son mujeres, pero no se confirma) etc.

Si bien, la pregunta de los interesados está enfocada a la implementación de una nueva campaña de marketing para la utilización de los productos de bellabeat sobre los de la competencia, yo consideraría la posibilidad de ampliar la cantidad de datos para obtener mejores resultados y un nivel de confianza aceptable. 

Para efectos del reto enfocaré los datos a esta pequeña población, tratándola como un punto de partida para la formulación de hipótesis que se podrán confirmar con un estudio posterior donde se observen cantidades de datos significativas.

Se acotará el analisis a las variables de pasos y calorias al ambas contener datos de los 33 usuarios.



## Procesar

Como se explicó anteriormente, se utilizará el lenguaje de programación R desde RStudio Desktop para este proyecto, así como el sitio de Github para su publicación y almacenamiento.

Se procede a buscar duplicados dentro del conjunto de datos.

```{r}
sum(duplicated(diario))
sum(duplicated(pasos))
sum(duplicated(calorias))

sum(is.na(diario))
sum(is.na(pasos))
sum(is.na(calorias))
```
Al no encontrarse duplicados en las variables de analisis ni  valores NA se procedió a buscar la cantidad de registros para cada usuario, es decir, la cantidad de dias que tenía cada usuario en su record diario.

```{r}
dias <- diario %>% group_by(Id) %>% 
     summarise(conteo_dias=n(),
               .groups = 'drop')
hist(dias$conteo_dias)
```

Mediante un histograma básico, se observó una cantidad distinta de registros para los usuarios.

Se considera reducir el análisis a solo los individuos con más de 25 registros para evitar sesgos por registros incompletos que lleguen a alterar las cifras completas, sin embargo, se plantea clasificar a los usuarios como usuarios que no utilizan los productos habitualmente y se busca aplicar un enfoque distinto creando una columna para el día de la semana en que se realizó el registro.

Para añadir esta variable se extrae de la columna de fecha el dia de la semana que se realizó el registro.

```{r}
diario <- diario %>% mutate( Dia_semana = weekdays(as.Date(ActivityDate, "%m/%d/%Y")))
head(diario)
```

La tabla diario contiene todas las variables de estudio y los datos de los usuarios reunidos en una única tabla, por lo que será seleccionada como principal.


Tras haber realizado esta manipulación de los datos, y tomar en cuenta las consideraciones previamente declaradas. Se procede al siguiente paso del proyecto.

## Analizar

Primeramente recordaremos los encabezados de nuestra tabla
```{r}
colnames(diario)
```

```{r}
summary(diario)
```

### Por dia de la semana

Para comparar los datos desde la perspectiva de día de la semana se exportó el archivo csv que por cuestiones de tiempo facilitó el análisis y la creación de gráficos.


write.csv(diario, file = "diario.csv")

```{r}
##diario$Dia_semana = factor(diario$Dia_semana, levels = c("lunes", "martes", "miércoles", "jueves", "sábado", "domingo"))
```

```{r}
df %>%
ggplot(data = diario, mapping = aes(x = Dia_semana, y = TotalSteps, fill = Dia_semana))+ geom_bar(stat = "identity", position = "dodge") + labs(title = "Pasos por dia de la semana") 
```

```{r}
library(forcats)
df %>%
ggplot(data = diario, mapping = aes(x = fct_rev(fct_reorder(Dia_semana, Calories)), y = TotalSteps, fill = Dia_semana))+ geom_bar(stat = "identity") + labs(title = "Pasos por dia de la semana") 
```
Para corroborar el uso de los dispositivos de Bellabeat por día de la semana se graficaron los registros
![Calorias por dia de la semana.](~/Bellabeat/Bellabeat/archive/1.png)
![Calorias por dia de la semana.](~/Bellabeat/Bellabeat/archive/2.png)


### Hipotesis de pesos
Aún cuando se descartó la importancia de la tabla de pesos resumiremos los datos para conocer las características de los usuarios que sí registraton datos.

```{r}
usuariospesos <- pesos %>% 
  select(Id, BMI, IsManualReport) %>% 
  group_by(Id, IsManualReport) %>%  
  summarise(IMCpromedio = mean(BMI), n = n())
arrange(usuariospesos, IMCpromedio)
```

De esta tabla esperaba obtener la cantidad de reportes efectuados manualmente considerando el IMC de la persona. Buscando una relación entre las variables, sin embargo, por la cantidad de datos se debe resolver primero que se obtengan los datos de más participantes. Considero que uno de los mejores indicadores de la salud de una persona es el Indice de Masa Corporal(BMI en inglés) y por tanto se me ocurre ofrecer paquetes de productos donde se utilicen productos que monitoreen el IMC para que la aplicación de Bellabeat ofrezca notificaciones cuando este se vea fuera de sus parámetros normales, pasando a un monitoreo activo de tu IMC.


```{r}

```






